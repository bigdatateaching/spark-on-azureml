{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to define and run a job on AzureML using Spark and external Spark libraries such as `spark-nlp`. This notebook is the _control plane_, meaning it creates a connection to the AzureML workspace, defines the job, and submits the job.\n",
    "\n",
    "**This Jupyter notebook should be run from within a compute instance on AzureML, in a Python kernel, specifically `Python 3.10 - SDK v2 (Python 3.10.11)`**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a client connection to the AzureML workspace\n",
    "\n",
    "The following cell creates a connection object called `azureml_client` which has a connection to the AzureML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, spark, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this authentication mechanism if you are running this notebook from your compute instance within Azure Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this authentication when running the control plane from the AzureML Compute Instance\n",
    "\n",
    "azureml_client = MLClient.from_config(\n",
    "    DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can also run this control plane notebook from your Laptop. You need to install the python libraries in the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1731375810369
    }
   },
   "outputs": [],
   "source": [
    "## Use this when running the control plane from your laptop\n",
    "ml_client = MLClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    workspace_name=\"prof-azureml\",\n",
    "    subscription_id=\"21ff0fc0-dd2c-450d-93b7-96eeb3699b22\",\n",
    "    resource_group_name=\"prof-azureml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a container image to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'sparknl-python-env', 'description': None, 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/21ff0fc0-dd2c-450d-93b7-96eeb3699b22/resourceGroups/prof-azureml/providers/Microsoft.MachineLearningServices/workspaces/prof-azureml/environments/sparknl-python-env/versions/1', 'Resource__source_path': '', 'base_path': '/Users/marck/class/dsan6000/working-repos/spark-on-azureml', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x127306270>, 'serialize': <msrest.serialization.Serializer object at 0x127324c50>, 'version': '1', 'conda_file': {'dependencies': ['python=3.10.3', {'pip': ['spark-nlp']}]}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"dependencies\": [\\n    \"python=3.10.3\",\\n    {\\n      \"pip\": [\\n        \"spark-nlp\"\\n      ]\\n    }\\n  ]\\n}'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "environment_object = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04\",\n",
    "    conda_file=\"sparknlp-environment.yml\",\n",
    "    name=\"sparknl-python-env\"\n",
    ")\n",
    "ml_client.environments.create_or_update(environment_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Spark-NLP jar to your working directory to be able to to add to the job cluster.\n",
    "\n",
    "You only need to do this once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the spark-nlp jar and save it locally. This needs to be done before submitting a job.\n",
    "import requests\n",
    "response = requests.get(\"https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/jars/spark-nlp-assembly-5.5.1.jar\")\n",
    "with open(\"spark-nlp-assembly-5.5.1.jar\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Job\n",
    "\n",
    "The following cell defines the job. It is an object of [Spark Class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.spark?view=azure-python) that contains the required information to run a job:\n",
    "\n",
    "For more information about the parameters used in the job definition, [read the documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-submit-spark-jobs?view=azureml-api-2&tabs=sdk#submit-a-standalone-spark-job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1731375844443
    }
   },
   "outputs": [],
   "source": [
    "sparknlp_job_def = spark(\n",
    "    display_name=\"sample-sparknlp-job-with-added-jar\",\n",
    "    code=\"./\",\n",
    "    entry={\"file\": \"sample-spark-nlp-job.py\"},\n",
    "    driver_cores=1,\n",
    "    driver_memory=\"7g\",\n",
    "    executor_instances=1,\n",
    "    executor_cores=1,\n",
    "    executor_memory=\"7g\",\n",
    "        resources={\n",
    "        \"instance_type\": \"Standard_E4S_V3\",\n",
    "        \"runtime_version\": \"3.4\",\n",
    "    },\n",
    "    jars=\"spark-nlp-assembly-5.5.1.jar\",\n",
    "    environment=\"sparknl-python-env@latest\",\n",
    "    identity=UserIdentityConfiguration()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the job\n",
    "\n",
    "The following cell takes the job you defined above and submits it. If you are submitting multiple jobs, you may want to create separate job definition objects for clarity. You can submit more than one job, just remember that each job will spin up a Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/Users/marck/class/dsan6000/working-repos/spark-on-azureml/spark-job-wiht-sparknlp' 'https://profazureml2671195828.blob.core.windows.net/98a3d076-30fc-4f96-9801-8bb472602950-11aoc90lc83pxjort2iq4gninj/spark-job-wiht-sparknlp' \n",
      "\n",
      "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n",
      "\u001b[32mUploading spark-job-wiht-sparknlp (612.17 MBs): 100%|██████████| 612165617/612165617 [00:07<00:00, 85140211.65it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparknlp_job = ml_client.jobs.create_or_update(sparknlp_job_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Job Studio URL\n",
    "\n",
    "Once you submit the job, you can navigate to it in the AzureML Studio and monitor it's progress. There are ways to do it through the SDK but for now just use the Studio. These are unattended jobs, which means you can shut down this notebook and the Compute Instance, but the job will go through it's lifecycle:\n",
    "\n",
    "- Job is submitted\n",
    "- Job is queued\n",
    "- Job is run\n",
    "- Job completes (assuming no errors)\n",
    "\n",
    "**Each job's Studio URL will be different.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1731375905109
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ml.azure.com/runs/upbeat_receipt_ngxxln2kfr?wsid=/subscriptions/21ff0fc0-dd2c-450d-93b7-96eeb3699b22/resourcegroups/prof-azureml/workspaces/prof-azureml&tid=fd571193-38cb-437b-bb55-60f28d67b643\n"
     ]
    }
   ],
   "source": [
    "print(sparknlp_job.studio_url)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
